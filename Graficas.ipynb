{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "def read_csv(csv_path, attributes_to_obtain=None):\n",
    "    with open(csv_path) as csv_file:\n",
    "        reader = csv.reader(csv_file)\n",
    "        csv_info = list(reader)\n",
    "    \n",
    "    df = pd.DataFrame.from_records(csv_info[1:], columns=csv_info[0])\n",
    "    if attributes_to_obtain is not None:\n",
    "        df = df[attributes_to_obtain]\n",
    "    df = df.apply(pd.to_numeric)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def getMeanMetrics(df):\n",
    "    mean_accuracy,std_accuracy = np.mean(df['accuracy'].values), np.std(df['accuracy'].values)\n",
    "    mean_recall,std_recall = np.mean(df['mean_recall'].values), np.std(df['mean_recall'].values)\n",
    "    mean_prec, std_prec = np.mean(df['mean_precision'].values), np.std(df['mean_precision'].values)\n",
    "    mean_F1, std_F1 = np.mean(df['mean_F1'].values), np.std(df['mean_F1'].values)\n",
    "\n",
    "    mean_metrics = [mean_accuracy, mean_recall, mean_prec, mean_F1]\n",
    "    std_metrics = [std_accuracy, std_recall, std_prec, std_F1]\n",
    "        \n",
    "    return mean_metrics, std_metrics\n",
    "\n",
    "def plot_mean_std(x_axis_list, y_axis_list, std, title, y_lim_inf, x_label, y_label):\n",
    "    plt.title(title)\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.ylim(y_lim_inf, 1)\n",
    "    x = np.array([1,2,3,4])\n",
    "    plt.errorbar(x[0], y_axis_list[0], std[0], linestyle='None', marker='o')\n",
    "    plt.errorbar(x[1], y_axis_list[1], std[1], linestyle='None', marker='^')\n",
    "    plt.errorbar(x[2], y_axis_list[2], std[2], linestyle='None', marker='*')\n",
    "    plt.errorbar(x[3], y_axis_list[3], std[3], linestyle='None', marker='s')\n",
    "    plt.xticks(x, x_axis_list)\n",
    "    #plt.show()\n",
    "    plt.savefig(title + '.png')\n",
    "    plt.close()\n",
    "\n",
    "def plot_graphs(csv_file):\n",
    "    #Getting dataset information from csv file\n",
    "    #df = read_csv(csv_file, ['cross_val', 'kfold','accuracy','mean_recall','mean_precision','mean_F1'])\n",
    "    df = read_csv(csv_file)\n",
    "    \n",
    "    dataset_name = os.path.basename(csv_file).split('_')[0] + '_' +os.path.basename(csv_file).split('_')[1]\n",
    "    reg_factor = os.path.basename(csv_file).split('_')[2]\n",
    "    layers = os.path.basename(csv_file).split('_')[3].split('-')[0]\n",
    "    \n",
    "    x = [str(x) for x in range(1,11)]\n",
    "    \n",
    "    ##################### Comparing all metrics vs number of decision Trees #####################\n",
    "    title = 'All metrics vs Kfold - ' + dataset_name + '. Fator Reg. = ' + str(reg_factor) + ',camadas=' + str(layers)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Kfold')\n",
    "    plt.ylabel('Metric value')\n",
    "    plt.plot(x, df['accuracy'].values, '-o')\n",
    "    plt.plot(x, df['mean_recall'], '-^')\n",
    "    plt.plot(x, df['mean_precision'], '-*')\n",
    "    plt.plot(x, df['mean_F1'], '-s')\n",
    "    plt.gca().legend(('accuracy','recall', 'precision', 'F1-Measure'))\n",
    "    #plt.show()\n",
    "    plt.savefig(title + '.png')\n",
    "    plt.close()\n",
    "\n",
    "    \n",
    "    ##################### Mean metrics(mean +- std) #####################\n",
    "    #Getting global mean and std\n",
    "    mean_metrics, std_metrics = getMeanMetrics(df)\n",
    "    title = 'Mean metrics - ' + dataset_name + '. Fator Reg. = ' + str(reg_factor) + ',camadas=' + str(layers)\n",
    "    if dataset_name == 'wine_dataset':\n",
    "        y_lim_inf = 0.9\n",
    "    elif dataset_name == 'ionosphere_dataset':\n",
    "        y_lim_inf = 0.75\n",
    "    elif dataset_name == 'pima_dataset':\n",
    "        y_lim_inf = 0.6\n",
    "    plot_mean_std(['Accuracy', 'Recall', 'Precision', 'F1-measure'], mean_metrics,std_metrics, title,y_lim_inf,'Métrica', 'Metric Value')\n",
    "    \n",
    "    ##################### Precision, Recall, F1 per class #####################\n",
    "    if dataset_name == 'ionosphere_dataset':\n",
    "        title1 = 'Recall Per Class - ' + dataset_name + '. Fator Reg. = ' + str(reg_factor) + ',camadas=' + str(layers)\n",
    "        ##################### Recall per Class #####################\n",
    "        plt.title(title1)\n",
    "        plt.xlabel('Kfold')\n",
    "        plt.ylabel('Metric value')\n",
    "        plt.plot(x, df['class_good_recall'].values, '-o')\n",
    "        plt.plot(x, df['class_bad_recall'].values, '-^')\n",
    "        plt.gca().legend(('Recall class good','Recall class bad'))\n",
    "        #plt.show()\n",
    "        plt.savefig(title1 + '.png')\n",
    "        plt.close()\n",
    "\n",
    "        ##################### Precision per Class #####################\n",
    "        title2 = 'Precision Per Class - ' + dataset_name + '. Fator Reg. = ' + str(reg_factor) + ',camadas=' + str(layers)\n",
    "        plt.title(title2)\n",
    "        plt.xlabel('Kfold')\n",
    "        plt.ylabel('Metric value')\n",
    "        plt.plot(x, df['class_good_precision'].values, '-o')\n",
    "        plt.plot(x, df['class_bad_precision'].values, '-^')\n",
    "        plt.gca().legend(('Precision class good','Precision class bad'))\n",
    "        #plt.show()\n",
    "        plt.savefig(title2 + '.png')\n",
    "        plt.close()\n",
    "\n",
    "        ##################### Recall per Class #####################\n",
    "        title3 = 'F1-measure Per Class - ' + dataset_name + '. Fator Reg. = ' + str(reg_factor) + ',camadas=' + str(layers)\n",
    "        plt.title(title3)\n",
    "        plt.xlabel('Kfold')\n",
    "        plt.ylabel('Metric value')\n",
    "        plt.plot(x, df['class_good_F1'].values, '-o')\n",
    "        plt.plot(x, df['class_bad_F1'].values, '-^')\n",
    "        plt.gca().legend(('F1-Measure class good','F1-Measure class bad'))\n",
    "        #plt.show()\n",
    "        plt.savefig(title3 + '.png')\n",
    "        plt.close()\n",
    "    elif dataset_name == 'pima_dataset':\n",
    "        ##################### Recall per Class #####################\n",
    "        title1 = 'Recall Per Class - ' + dataset_name + '. Fator Reg. = ' + str(reg_factor) + ',camadas=' + str(layers)\n",
    "        plt.title(title1)\n",
    "        plt.xlabel('Kfold')\n",
    "        plt.ylabel('Metric value')\n",
    "        plt.plot(x, df['class_0_recall'].values, '-o')\n",
    "        plt.plot(x, df['class_1_recall'].values, '-^')\n",
    "        plt.gca().legend(('Recall class 0','Recall class 1'))\n",
    "        #plt.show()\n",
    "        plt.savefig(title1 + '.png')\n",
    "        plt.close()\n",
    "\n",
    "        ##################### Precision per Class #####################\n",
    "        title2 = 'Precision Per Class - ' + dataset_name + '. Fator Reg. = ' + str(reg_factor) + ',camadas=' + str(layers)\n",
    "        plt.title(title2)\n",
    "        plt.xlabel('Kfold')\n",
    "        plt.ylabel('Metric value')\n",
    "        plt.plot(x, df['class_0_precision'].values, '-o')\n",
    "        plt.plot(x, df['class_1_precision'].values, '-^')\n",
    "        plt.gca().legend(('Precision class 0','Precision class 1'))\n",
    "        #plt.show()\n",
    "        plt.savefig(title2 + '.png')\n",
    "        plt.close()\n",
    "\n",
    "        ##################### Recall per Class #####################\n",
    "        title3 = 'F1-measure Per Class - ' + dataset_name + '. Fator Reg. = ' + str(reg_factor) + ',camadas=' + str(layers)\n",
    "        plt.title(title3)\n",
    "        plt.xlabel('Kfold')\n",
    "        plt.ylabel('Metric value')\n",
    "        plt.plot(x, df['class_0_F1'].values, '-o')\n",
    "        plt.plot(x, df['class_1_F1'].values, '-^')\n",
    "        plt.gca().legend(('F1-Measure class 0','F1-Measure class 1'))\n",
    "        #plt.show()\n",
    "        plt.savefig(title3 + '.png')\n",
    "        plt.close()\n",
    "    elif dataset_name == 'wine_dataset':\n",
    "        \n",
    "        ##################### Recall per Class #####################\n",
    "        title1 = 'Recall Per Class - ' + dataset_name + '. Fator Reg. = ' + str(reg_factor) + ',camadas=' + str(layers)\n",
    "        plt.title(title1)\n",
    "        plt.xlabel('Kfold')\n",
    "        plt.ylabel('Metric value')\n",
    "        plt.plot(x, df['class_1_recall'].values, '-o')\n",
    "        plt.plot(x, df['class_2_recall'].values, '-^')\n",
    "        plt.plot(x, df['class_3_recall'].values, '-*')\n",
    "        plt.gca().legend(('Recall class 1','Recall class 2', 'Recall class 3'))\n",
    "        #plt.show()\n",
    "        plt.savefig(title1 + '.png')\n",
    "        plt.close()\n",
    "\n",
    "        ##################### Precision per Class #####################\n",
    "        title2 = 'Precision Per Class - ' + dataset_name + '. Fator Reg. = ' + str(reg_factor) + ',camadas=' + str(layers)\n",
    "        plt.title(title2)\n",
    "        plt.xlabel('Kfold')\n",
    "        plt.ylabel('Metric value')\n",
    "        plt.plot(x, df['class_1_precision'].values, '-o')\n",
    "        plt.plot(x, df['class_2_precision'].values, '-^')\n",
    "        plt.plot(x, df['class_3_precision'].values, '-*')\n",
    "        plt.gca().legend(('Precision class 1','Precision class 2', 'Precision class 3'))\n",
    "        #plt.show()\n",
    "        plt.savefig(title2 + '.png')\n",
    "        plt.close()\n",
    "\n",
    "        ##################### Recall per Class #####################\n",
    "        title3 = 'F1-measure Per Class - ' + dataset_name + '. Fator Reg. = ' + str(reg_factor) + ',camadas=' + str(layers)\n",
    "        plt.title(title3)\n",
    "        plt.xlabel('Kfold')\n",
    "        plt.ylabel('Metric value')\n",
    "        plt.plot(x, df['class_1_F1'].values, '-o')\n",
    "        plt.plot(x, df['class_2_F1'].values, '-^')\n",
    "        plt.plot(x, df['class_1_F1'].values, '-*')\n",
    "        plt.gca().legend(('F1-Measure class 1','F1-Measure  class 2', 'F1-Measure  class 3'))\n",
    "        #plt.show()\n",
    "        plt.savefig(title3 + '.png')\n",
    "        plt.close()\n",
    "            \n",
    "def export_as_csv(mylist, csv_file_path):\n",
    "    print(csv_file_path)\n",
    "    for index,row in enumerate(mylist):\n",
    "        if index == 0:\n",
    "            mode = 'w'\n",
    "        else:\n",
    "            mode = 'a'\n",
    "        \n",
    "        with open(csv_file_path, mode=mode) as csv_file:\n",
    "            csv_writer = csv.writer(csv_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "            csv_writer.writerow(list(row))\n",
    "            \n",
    "def generate_table(dir_of_csvs):\n",
    "    table_elements = []\n",
    "    table_elements.append(['Reg. Factor', 'Network Struc.', 'Accuracy', 'F1-Measure', 'Recall', 'Precision'])\n",
    "    for root, dirs, files in os.walk(dir_of_csvs):\n",
    "        for file in files:\n",
    "            metrics = read_csv(os.path.join(root,file))\n",
    "            reg_factor = file.split('_')[2]\n",
    "            network_struc = file.split('_')[3].split('-')[0]\n",
    "            str_acc = str(round(metrics['accuracy'].mean(), 4)) + ' ± ' + str(round(metrics['accuracy'].std(), 4))\n",
    "            str_F1 = str(round(metrics['mean_F1'].mean(), 4)) + ' ± ' + str(round(metrics['mean_F1'].std(), 4))\n",
    "            str_recall = str(round(metrics['mean_recall'].mean(), 4)) + ' ± ' + str(round(metrics['mean_recall'].std(), 4))\n",
    "            str_prec = str(round(metrics['mean_precision'].mean(), 4)) + ' ± ' + str(round(metrics['mean_precision'].std(), 4))\n",
    "            element = [reg_factor, network_struc, str_acc,str_F1,str_recall, str_prec]\n",
    "            table_elements.append(element)\n",
    "    \n",
    "    sorted_list = sorted(table_elements,key=lambda l:l[3], reverse=True)\n",
    "    export_as_csv(sorted_list, os.path.basename(dir_of_csvs) + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#wine dataset\n",
    "#generate_table('datasets/wine_dataset_alpha_0.1_patience_400')\n",
    "#generate_table('datasets/wine_dataset_alpha_0.15_patience_400')\n",
    "#generate_table('datasets/wine_dataset_alpha_0.20_patience_400')\n",
    "plot_graphs('results/cross_validation/wine_dataset_alpha_0.20_patience_400/wine_dataset_0.1_[13, 3, 3]-metrics.csv')\n",
    "\n",
    "#ionosphere dataset\n",
    "#generate_table('datasets/ionosphere_dataset_alpha_0.1_patience_600')\n",
    "#generate_table('datasets/ionosphere_dataset_alpha_0.15_patience_600')\n",
    "#generate_table('datasets/ionosphere_dataset_alpha_0.20_patience_600')\n",
    "plot_graphs('results/cross_validation/ionosphere_dataset_alpha_0.20_patience_600/ionosphere_dataset_0.1_[34, 2, 1, 2]-metrics.csv')\n",
    "\n",
    "#Pima dataset\n",
    "#generate_table('datasets/pima_dataset_alpha_0.1_patience_800')\n",
    "#generate_table('datasets/pima_dataset_alpha_0.15_patience_800')\n",
    "#generate_table('datasets/pima_dataset_alpha_0.20_patience_800')\n",
    "plot_graphs('results/cross_validation/pima_dataset_alpha_0.20_patience_800/pima_dataset_0.05_[8, 2, 1, 2]-metrics.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
